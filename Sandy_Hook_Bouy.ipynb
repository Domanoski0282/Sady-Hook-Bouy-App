{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Domanoski0282/Sady-Hook-Bouy-App/blob/main/Sandy_Hook_Bouy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Sandy Hook Live Ocean Summary Monitor\n",
        "Fetches data from NDBC 44065 (wave data) and CO-OPS 8531680 (tide data)\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import os\n",
        "import signal\n",
        "import sys\n",
        "from typing import Optional, Dict, List, Tuple, Any\n",
        "import numpy as np\n",
        "\n",
        "# Station IDs\n",
        "NDBC_STATION = \"44065\"  # Sandy Hook wave buoy\n",
        "COOPS_STATION = \"8531680\"  # Sandy Hook tide gauge\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"./sandy_hook_output\"\n",
        "\n",
        "\n",
        "class GracefulExit:\n",
        "    \"\"\"Handle graceful shutdown on KeyboardInterrupt\"\"\"\n",
        "    def __init__(self):\n",
        "        self.shutdown = False\n",
        "        signal.signal(signal.SIGINT, self.exit_gracefully)\n",
        "        signal.signal(signal.SIGTERM, self.exit_gracefully)\n",
        "\n",
        "    def exit_gracefully(self, signum, frame):\n",
        "        print(\"\\n\\nKeyboardInterrupt received — exiting.\")\n",
        "        self.shutdown = True\n",
        "        sys.exit(0)\n",
        "\n",
        "\n",
        "def ensure_output_dir():\n",
        "    \"\"\"Create output directory if it doesn't exist\"\"\"\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def fetch_ndbc_realtime(station_id: str) -> Optional[Dict]:\n",
        "    \"\"\"Fetch real-time data from NDBC station\"\"\"\n",
        "    try:\n",
        "        url = f\"https://www.ndbc.noaa.gov/data/realtime2/{station_id}.txt\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        lines = response.text.strip().split('\\n')\n",
        "        if len(lines) < 2:\n",
        "            return None\n",
        "\n",
        "        # Parse header\n",
        "        header = lines[0].split()\n",
        "        # Parse latest data line\n",
        "        data_line = lines[-1].split()\n",
        "\n",
        "        if len(data_line) < len(header):\n",
        "            return None\n",
        "\n",
        "        data = dict(zip(header, data_line))\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching NDBC data: {e}\", file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "\n",
        "def fetch_ndbc_historical(station_id: str, hours: int = 6) -> Optional[List[Dict]]:\n",
        "    \"\"\"Fetch historical data from NDBC for specified hours\"\"\"\n",
        "    try:\n",
        "        # NDBC provides data in various formats, try the standard realtime format\n",
        "        url = f\"https://www.ndbc.noaa.gov/data/realtime2/{station_id}.txt\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        lines = response.text.strip().split('\\n')\n",
        "        if len(lines) < 2:\n",
        "            return None\n",
        "\n",
        "        # NDBC format: first line is header, second line is units (skip), then data\n",
        "        header_line = lines[0]\n",
        "        # Skip units line if present\n",
        "        data_start = 1\n",
        "        if len(lines) > 1 and any(unit in lines[1].lower() for unit in ['deg', 'm', 's', 'hpa']):\n",
        "            data_start = 2\n",
        "\n",
        "        header = header_line.split()\n",
        "        data_points = []\n",
        "\n",
        "        # Parse all data lines\n",
        "        for line in lines[data_start:]:\n",
        "            if not line.strip() or line.strip().startswith('#'):\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            # NDBC data lines have date/time first, then measurements\n",
        "            # Match parts to header, handling variable spacing\n",
        "            if len(parts) >= len(header):\n",
        "                # Create dict, handling cases where we have more parts than headers\n",
        "                data_dict = {}\n",
        "                for i, key in enumerate(header):\n",
        "                    if i < len(parts):\n",
        "                        data_dict[key] = parts[i]\n",
        "                    else:\n",
        "                        data_dict[key] = 'MM'  # Missing\n",
        "                data_points.append(data_dict)\n",
        "\n",
        "        # NDBC realtime data typically has ~45 recent measurements\n",
        "        # Filter to approximate hours (assuming ~1 measurement per hour, but often more frequent)\n",
        "        # For 6 hours, we might get 6-12 data points depending on station\n",
        "        return data_points[-hours*2:] if len(data_points) > hours*2 else data_points\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching NDBC historical data: {e}\", file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "\n",
        "def fetch_coops_tide_data(station_id: str, hours: int = 6) -> Optional[List[Dict]]:\n",
        "    \"\"\"Fetch tide data from CO-OPS API\"\"\"\n",
        "    try:\n",
        "        end_time = datetime.now(timezone.utc)\n",
        "        start_time = end_time - timedelta(hours=hours)\n",
        "\n",
        "        url = \"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter\"\n",
        "        params = {\n",
        "            \"product\": \"water_level\",\n",
        "            \"application\": \"NOS.COOPS.TAC.WL\",\n",
        "            \"begin_date\": start_time.strftime(\"%Y%m%d %H:%M\"),\n",
        "            \"end_date\": end_time.strftime(\"%Y%m%d %H:%M\"),\n",
        "            \"datum\": \"MLLW\",\n",
        "            \"station\": station_id,\n",
        "            \"time_zone\": \"gmt\",\n",
        "            \"units\": \"metric\",\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if 'data' in data:\n",
        "            return data['data']\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching CO-OPS tide data: {e}\", file=sys.stderr)\n",
        "        return None\n",
        "\n",
        "\n",
        "def parse_float(value: str) -> Optional[float]:\n",
        "    \"\"\"Safely parse float, handling NDBC 'MM' (missing) values\"\"\"\n",
        "    if not value or value in ['MM', '']:\n",
        "        return None\n",
        "    try:\n",
        "        return float(value)\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_wave_stats(data_points: List[Dict], hours: int) -> Tuple[Optional[float], Optional[float]]:\n",
        "    \"\"\"Calculate average and max wave height from data points\"\"\"\n",
        "    if not data_points:\n",
        "        return None, None\n",
        "\n",
        "    wave_heights = []\n",
        "    for point in data_points:\n",
        "        # NDBC uses 'WVHT' for wave height\n",
        "        wvht = parse_float(point.get('WVHT', point.get('wvht', '')))\n",
        "        if wvht is not None:\n",
        "            wave_heights.append(wvht)\n",
        "\n",
        "    if not wave_heights:\n",
        "        return None, None\n",
        "\n",
        "    avg = np.mean(wave_heights)\n",
        "    max_val = np.max(wave_heights)\n",
        "    return avg, max_val\n",
        "\n",
        "\n",
        "def calculate_dominant_period(data_points: List[Dict]) -> Optional[float]:\n",
        "    \"\"\"Calculate dominant wave period\"\"\"\n",
        "    if not data_points:\n",
        "        return None\n",
        "\n",
        "    periods = []\n",
        "    for point in data_points:\n",
        "        # NDBC uses 'DPD' for dominant period\n",
        "        dpd = parse_float(point.get('DPD', point.get('dpd', '')))\n",
        "        if dpd is not None:\n",
        "            periods.append(dpd)\n",
        "\n",
        "    if not periods:\n",
        "        return None\n",
        "\n",
        "    return np.mean(periods)\n",
        "\n",
        "\n",
        "def calculate_mean_direction(data_points: List[Dict]) -> Optional[float]:\n",
        "    \"\"\"Calculate mean wave direction\"\"\"\n",
        "    if not data_points:\n",
        "        return None\n",
        "\n",
        "    directions = []\n",
        "    for point in data_points:\n",
        "        # NDBC uses 'MWD' for mean wave direction\n",
        "        mwd = parse_float(point.get('MWD', point.get('mwd', '')))\n",
        "        if mwd is not None:\n",
        "            directions.append(mwd)\n",
        "\n",
        "    if not directions:\n",
        "        return None\n",
        "\n",
        "    return np.mean(directions)\n",
        "\n",
        "\n",
        "def calculate_pressure_change(data_points: List[Dict], hours: int = 6) -> Optional[float]:\n",
        "    \"\"\"Calculate pressure change over specified hours\"\"\"\n",
        "    if not data_points or len(data_points) < 2:\n",
        "        return None\n",
        "\n",
        "    # Get first and last valid pressure readings\n",
        "    pressures = []\n",
        "    for point in data_points:\n",
        "        pres = parse_float(point.get('PRES', point.get('pres', '')))\n",
        "        if pres is not None:\n",
        "            pressures.append(pres)\n",
        "\n",
        "    if len(pressures) < 2:\n",
        "        return None\n",
        "\n",
        "    return pressures[-1] - pressures[0]\n",
        "\n",
        "\n",
        "def calculate_tide_range(tide_data: List[Dict]) -> Optional[float]:\n",
        "    \"\"\"Calculate tide range from CO-OPS data\"\"\"\n",
        "    if not tide_data:\n",
        "        return None\n",
        "\n",
        "    water_levels = []\n",
        "    for point in tide_data:\n",
        "        try:\n",
        "            level = float(point.get('v', 0))\n",
        "            water_levels.append(level)\n",
        "        except (ValueError, TypeError):\n",
        "            continue\n",
        "\n",
        "    if not water_levels:\n",
        "        return None\n",
        "\n",
        "    return max(water_levels) - min(water_levels)\n",
        "\n",
        "\n",
        "def detect_anomaly(data_points: List[Dict], threshold: float = 0.20) -> bool:\n",
        "    \"\"\"Detect if there's a rapid change (>threshold) in recent data\"\"\"\n",
        "    if not data_points or len(data_points) < 2:\n",
        "        return False\n",
        "\n",
        "    # Get recent wave heights\n",
        "    wave_heights = []\n",
        "    for point in data_points[-6:]:  # Last 6 data points\n",
        "        wvht = parse_float(point.get('WVHT', point.get('wvht', '')))\n",
        "        if wvht is not None:\n",
        "            wave_heights.append(wvht)\n",
        "\n",
        "    if len(wave_heights) < 2:\n",
        "        return False\n",
        "\n",
        "    # Calculate percentage change\n",
        "    recent_avg = np.mean(wave_heights[-3:]) if len(wave_heights) >= 3 else wave_heights[-1]\n",
        "    previous_avg = np.mean(wave_heights[:-3]) if len(wave_heights) >= 6 else wave_heights[0]\n",
        "\n",
        "    if previous_avg == 0:\n",
        "        return False\n",
        "\n",
        "    change = abs((recent_avg - previous_avg) / previous_avg)\n",
        "    return change > threshold\n",
        "\n",
        "\n",
        "def format_value(value: Optional[float], unit: str = \"\", decimals: int = 2) -> str:\n",
        "    \"\"\"Format a value, handling None/nan\"\"\"\n",
        "    if value is None or np.isnan(value):\n",
        "        return \"nan\"\n",
        "    return f\"{value:.{decimals}f} {unit}\".strip()\n",
        "\n",
        "\n",
        "def print_summary(ndbc_data_1h: List[Dict], ndbc_data_6h: List[Dict],\n",
        "                  tide_data: List[Dict], retrieval_time: datetime):\n",
        "    \"\"\"Print the summary report\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Sandy Hook Live Ocean Summary  (NDBC {NDBC_STATION}  |  CO-OPS {COOPS_STATION})\")\n",
        "    print(f\"\\nRetrieval UTC: {retrieval_time.strftime('%Y-%m-%d %H:%M:%SZ')}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Calculate statistics\n",
        "    avg_wvht_1h, max_wvht_1h = calculate_wave_stats(ndbc_data_1h, 1)\n",
        "    avg_wvht_6h, max_wvht_6h = calculate_wave_stats(ndbc_data_6h, 6)\n",
        "    dom_period = calculate_dominant_period(ndbc_data_6h)\n",
        "    mean_dir = calculate_mean_direction(ndbc_data_6h)\n",
        "    pressure_change = calculate_pressure_change(ndbc_data_6h, 6)\n",
        "    tide_range = calculate_tide_range(tide_data)\n",
        "    anomaly = detect_anomaly(ndbc_data_6h, 0.20)\n",
        "\n",
        "    # Print formatted output\n",
        "    print(f\"\\nAvg WVHT 1h:   {format_value(avg_wvht_1h, 'm', 2)}   | Max WVHT 1h: {format_value(max_wvht_1h, 'm', 2)}\")\n",
        "    print(f\"Avg WVHT 6h:   {format_value(avg_wvht_6h, 'm', 2)}   | Max WVHT 6h: {format_value(max_wvht_6h, 'm', 2)}\")\n",
        "    print(f\"Dom Period:    {format_value(dom_period, 's', 1)}   | Mean Dir: {format_value(mean_dir, '° (true)', 0)}\")\n",
        "    print(f\"Wind–Wave r:   {format_value(None)}\")  # Placeholder for wind-wave relationship\n",
        "    print(f\"\\nΔPressure 6h:  {format_value(pressure_change, 'hPa', 2)}\")\n",
        "    print(f\"Tide range 6h: {format_value(tide_range, 'm', 2)}\")\n",
        "    print(f\"\\nAnomaly >20%?  {'YES' if anomaly else 'NO'}\")\n",
        "\n",
        "    print(\"\\n----\")\n",
        "    if anomaly:\n",
        "        print(\"Interpretation: Rapid change (>20%) detected within last hour—monitor for short-term hazards.\", end=\"\")\n",
        "    else:\n",
        "        print(\"Interpretation: No significant rapid changes detected.\", end=\"\")\n",
        "\n",
        "    if tide_range is not None:\n",
        "        print(f\" 6-hr tide range ~{tide_range:.2f} m at Sandy Hook.\")\n",
        "    else:\n",
        "        print(\" Tide data unavailable.\")\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "def convert_to_json_serializable(obj: Any) -> Any:\n",
        "    \"\"\"Convert numpy types and other non-serializable objects to JSON-compatible types\"\"\"\n",
        "    # Handle numpy types\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        if np.isnan(obj):\n",
        "            return None\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, (np.bool_, bool)):\n",
        "        return bool(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    # Handle nested structures\n",
        "    elif isinstance(obj, dict):\n",
        "        return {key: convert_to_json_serializable(value) for key, value in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return [convert_to_json_serializable(item) for item in obj]\n",
        "    elif obj is None:\n",
        "        return None\n",
        "    else:\n",
        "        # For any other type, try to convert to string as fallback\n",
        "        try:\n",
        "            json.dumps(obj)  # Test if it's already serializable\n",
        "            return obj\n",
        "        except (TypeError, ValueError):\n",
        "            return str(obj)\n",
        "\n",
        "\n",
        "def save_output(ndbc_data_1h: List[Dict], ndbc_data_6h: List[Dict],\n",
        "                tide_data: List[Dict], retrieval_time: datetime):\n",
        "    \"\"\"Save output to file\"\"\"\n",
        "    ensure_output_dir()\n",
        "    timestamp = retrieval_time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = os.path.join(OUTPUT_DIR, f\"sandy_hook_summary_{timestamp}.json\")\n",
        "\n",
        "    output = {\n",
        "        \"retrieval_time\": retrieval_time.isoformat(),\n",
        "        \"ndbc_station\": NDBC_STATION,\n",
        "        \"coops_station\": COOPS_STATION,\n",
        "        \"ndbc_data_1h\": ndbc_data_1h,\n",
        "        \"ndbc_data_6h\": ndbc_data_6h,\n",
        "        \"tide_data\": tide_data,\n",
        "        \"statistics\": {\n",
        "            \"avg_wvht_1h\": calculate_wave_stats(ndbc_data_1h, 1)[0],\n",
        "            \"max_wvht_1h\": calculate_wave_stats(ndbc_data_1h, 1)[1],\n",
        "            \"avg_wvht_6h\": calculate_wave_stats(ndbc_data_6h, 6)[0],\n",
        "            \"max_wvht_6h\": calculate_wave_stats(ndbc_data_6h, 6)[1],\n",
        "            \"dom_period\": calculate_dominant_period(ndbc_data_6h),\n",
        "            \"mean_dir\": calculate_mean_direction(ndbc_data_6h),\n",
        "            \"pressure_change_6h\": calculate_pressure_change(ndbc_data_6h, 6),\n",
        "            \"tide_range_6h\": calculate_tide_range(tide_data),\n",
        "            \"anomaly_detected\": detect_anomaly(ndbc_data_6h, 0.20)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Convert numpy types to JSON-serializable types\n",
        "        output_serializable = convert_to_json_serializable(output)\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(output_serializable, f, indent=2)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving output: {e}\", file=sys.stderr)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main monitoring loop\"\"\"\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Sandy Hook Ocean Monitoring')\n",
        "    parser.add_argument('--once', action='store_true',\n",
        "                       help='Run once and exit (for testing)')\n",
        "    parser.add_argument('--interval', type=int, default=3600,\n",
        "                       help='Update interval in seconds (default: 3600 = 1 hour)')\n",
        "    # Use parse_known_args to ignore Jupyter/Colab kernel arguments\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    exit_handler = GracefulExit()\n",
        "\n",
        "    print(\"Starting Sandy Hook monitor. Output dir: \" + OUTPUT_DIR)\n",
        "\n",
        "    try:\n",
        "        while not exit_handler.shutdown:\n",
        "            retrieval_time = datetime.now(timezone.utc)\n",
        "\n",
        "            # Fetch data\n",
        "            ndbc_data_6h = fetch_ndbc_historical(NDBC_STATION, 6)\n",
        "            ndbc_data_1h = ndbc_data_6h[-1:] if ndbc_data_6h else []\n",
        "            tide_data = fetch_coops_tide_data(COOPS_STATION, 6)\n",
        "\n",
        "            # Print summary\n",
        "            print_summary(ndbc_data_1h or [], ndbc_data_6h or [], tide_data or [], retrieval_time)\n",
        "\n",
        "            # Save output\n",
        "            save_output(ndbc_data_1h or [], ndbc_data_6h or [], tide_data or [], retrieval_time)\n",
        "\n",
        "            # Exit if --once flag is set\n",
        "            if args.once:\n",
        "                break\n",
        "\n",
        "            # Wait before next update\n",
        "            if not exit_handler.shutdown:\n",
        "                time.sleep(args.interval)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nKeyboardInterrupt received — exiting.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError in main loop: {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "hBQ2EVigutQ5",
        "outputId": "860311dc-7ada-451a-fc28-fae2097afbb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sandy Hook monitor. Output dir: ./sandy_hook_output\n",
            "\n",
            "============================================================\n",
            "Sandy Hook Live Ocean Summary  (NDBC 44065  |  CO-OPS 8531680)\n",
            "\n",
            "Retrieval UTC: 2025-12-12 22:42:32Z\n",
            "============================================================\n",
            "\n",
            "Avg WVHT 1h:   nan   | Max WVHT 1h: nan\n",
            "Avg WVHT 6h:   0.64 m   | Max WVHT 6h: 0.70 m\n",
            "Dom Period:    11.2 s   | Mean Dir: 124 ° (true)\n",
            "Wind–Wave r:   nan\n",
            "\n",
            "ΔPressure 6h:  -0.20 hPa\n",
            "Tide range 6h: 0.62 m\n",
            "\n",
            "Anomaly >20%?  NO\n",
            "\n",
            "----\n",
            "Interpretation: No significant rapid changes detected. 6-hr tide range ~0.62 m at Sandy Hook.\n",
            "\n",
            "\n",
            "\n",
            "KeyboardInterrupt received — exiting.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "0",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8aA3AtfJNDKE+eD4ul7KV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}